{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR-jeyP-An8"
      },
      "source": [
        "# ‚ú® README\n",
        "\n",
        "This is the companion Colab for the article \"[How to transcribe your audio to text, for free (with SRTs/VTTs!)](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0)\".\n",
        "\n",
        "This Colab shows how to use OpenAI's Whisper to transcribe audio and audiovisual files, and how to save that transcription as a plain text file or as a VTT/SRT caption file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìé Documentation\n",
        "\n",
        "* `input_format`: The source of the audio/video file to be transcribed\n",
        "  * `youtube`: A YouTube video\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "  * `gdrive`: A file in your Google Drive account\n",
        "    * If you select this option, you will need to allow this notebook to connect to your Google Drive account.\n",
        "    * The transcribed file(s) are saved to the same folder as the original file.\n",
        "  * `local`: A local file that you have uploaded to this Colab\n",
        "    * If you select this option, you will need to first upload the file to the Files tab (see Step 1 [here](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozMzc1MzU3)).\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "* `file`: The URL of the YouTube video or the path of the audio file to be transcribed.\n",
        "  * Example: `file = \"https://www.youtube.com/watch?v=AUDIO\"` (transcribing a YouTube video)\n",
        "  * Example: `file = \"/content/drive/My Drive/AUDIO.mp3\"` (transcribing a Google Drive file)\n",
        "  * Example: `file = \"/content/AUDIO.mp3\"` (transcribing a local file)\n",
        "* `plain`: Whether to save the transcription as a text file or not.\n",
        "* `srt`: Whether to save the transcription as an SRT file or not.\n",
        "* `vtt`: Whether to save the transcription as a VTT file or not.\n",
        "* `tsv`: Whether to save the transcription as a TSV (tab-separated values) file or not.\n",
        "* `download`: Whether to download the transcribed file(s) or not.\n"
      ],
      "metadata": {
        "id": "EjLJ6mHptbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üå¥ Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"local\" #@param [\"youtube\", \"gdrive\", \"local\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "file = \"/content/lilyweek2.m4a\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "download = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "fAQKStuINe3G",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# üõ† Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ù Dependencies"
      ],
      "metadata": {
        "id": "hfnRc8yPM79j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "outputId": "34680268-8b50-488a-88bd-79661abdca19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëã Whisper configuration\n",
        "\n",
        "This Colab use `medium.en`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ],
      "metadata": {
        "id": "E4eLQzNOo5_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"medium.en\").to(DEVICE)"
      ],
      "metadata": {
        "id": "YCNc3EfV4EIt",
        "outputId": "756e61bc-62fd-4c6c-d0b6-9dec4d390f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:31<00:00, 49.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üí™ YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ],
      "metadata": {
        "id": "IvN1wRXbo-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
        "    \"Download the audio from a YouTube video\"\n",
        "    yt = YouTube(url)\n",
        "    if file_name is None:\n",
        "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "    yt = (yt.streams\n",
        "            .filter(only_audio = True, file_extension = \"mp4\")\n",
        "            .order_by(\"abr\")\n",
        "            .desc())\n",
        "    return yt.first().download(filename = file_name)"
      ],
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úç Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ],
      "metadata": {
        "id": "ech5wPCwtO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "\n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "\n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "\n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "\n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = Path(file)\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file, verbose = False, language = \"en\")\n",
        "\n",
        "    if plain:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nCreating text file\")\n",
        "\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "\n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ Whisper it!\n",
        "\n",
        "This block actually calls `transcribe_file` üòâ\n"
      ],
      "metadata": {
        "id": "CLC_tpz6tgq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if input_format == \"youtube\":\n",
        "    # Download the audio stream of the YouTube video\n",
        "    print(f\"Downloading audio stream: {audio}\")\n",
        "    audio = download_youtube_audio(file)\n",
        "\n",
        "    # Run Whisper on the audio stream\n",
        "    result = transcribe_file(model, audio, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"gdrive\":\n",
        "    # Authorize a connection between Google Drive and Google Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"local\":\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)"
      ],
      "metadata": {
        "id": "ngTGllHutSfo",
        "outputId": "cb07ad75-447c-4198-f146-ad953c648084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: /content/lilyweek2.m4a\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109651/109651 [01:50<00:00, 993.67frames/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating text file\n",
            "Downloading /content/lilyweek2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_559921bb-6f5c-4fef-a2b1-230955e16b72\", \"lilyweek2.txt\", 8751)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}